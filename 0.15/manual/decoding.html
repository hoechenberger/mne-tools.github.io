<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Decoding in MNE &#8212; MNE 0.15 documentation</title>
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.15',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />

    <script type="text/javascript" src="../_static/copybutton.js"></script>


    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37225609-1']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>


    <link rel="stylesheet" href="../_static/style.css " type="text/css" />
    <link rel="stylesheet" href="../_static/font-awesome.css" type="text/css" />
    <link rel="stylesheet" href="../_static/flag-icon.css" type="text/css" />



    <script type="text/javascript">
    !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);
    js.id=id;js.src="https://platform.twitter.com/widgets.js";
    fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");
    </script>



    <script type="text/javascript">
    (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
    })();
    </script>


  <link rel="canonical" href="https://mne.tools/stable/index.html" />
</head>
  <body>





  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/mne_logo_small.png"></span>
           </a>
        <span class="navbar-text navbar-version pull-left"><b>0.15</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../getting_started.html">Install</a></li>
                <li><a href="../documentation.html">Documentation</a></li>
                <li><a href="../python_reference.html">API</a></li>
                <li><a href="../auto_examples/index.html">Examples</a></li>
                <li><a href="../contributing.html">Contribute</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
<div class="navbar-form navbar-right navbar-btn dropdown btn-group-sm" style="margin-left: 20px; margin-top: 5px; margin-bottom: 5px">
  <button type="button" class="btn btn-primary navbar-btn dropdown-toggle" id="dropdownMenu1" data-toggle="dropdown">
    v0.15
    <span class="caret"></span>
  </button>
  <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
    <li><a href="https://mne-tools.github.io/dev/index.html">Development</a></li>
    <li><a href="https://mne-tools.github.io/stable/index.html">v0.15 (stable)</a></li>
    <li><a href="https://mne-tools.github.io/0.14/index.html">v0.14</a></li>
    <li><a href="https://mne-tools.github.io/0.13/index.html">v0.13</a></li>
    <li><a href="https://mne-tools.github.io/0.12/index.html">v0.12</a></li>
    <li><a href="https://mne-tools.github.io/0.11/index.html">v0.11</a></li>
  </ul>
</div>


            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          

        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/mne_logo_small.png" alt="Logo"/>
            </a></p><ul>
<li><a class="reference internal" href="#">Decoding in MNE</a><ul>
<li><a class="reference internal" href="#basic-estimators">Basic Estimators</a><ul>
<li><a class="reference internal" href="#scaler">Scaler</a></li>
<li><a class="reference internal" href="#vectorizer">Vectorizer</a></li>
<li><a class="reference internal" href="#psdestimator">PSDEstimator</a></li>
<li><a class="reference internal" href="#filterestimator">FilterEstimator</a></li>
</ul>
</li>
<li><a class="reference internal" href="#spatial-filters">Spatial filters</a><ul>
<li><a class="reference internal" href="#common-spatial-pattern">Common Spatial Pattern</a></li>
<li><a class="reference internal" href="#source-power-comodulation-spoc">Source Power Comodulation (SPoC)</a></li>
<li><a class="reference internal" href="#xdawn">xDAWN</a></li>
<li><a class="reference internal" href="#effect-matched-spatial-filtering">Effect-matched spatial filtering</a></li>
<li><a class="reference internal" href="#patterns-vs-filters">Patterns vs. filters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sensor-space-decoding">Sensor-space decoding</a><ul>
<li><a class="reference internal" href="#decoding-over-time">Decoding over time</a></li>
<li><a class="reference internal" href="#temporal-generalization">Temporal Generalization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#source-space-decoding">Source-space decoding</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

<form action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
        </div>
      </div>
    <div class="col-md-12 content">
      
  <div class="contents local topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#decoding-in-mne" id="id3">Decoding in MNE</a><ul>
<li><a class="reference internal" href="#basic-estimators" id="id4">Basic Estimators</a><ul>
<li><a class="reference internal" href="#scaler" id="id5">Scaler</a></li>
<li><a class="reference internal" href="#vectorizer" id="id6">Vectorizer</a></li>
<li><a class="reference internal" href="#psdestimator" id="id7">PSDEstimator</a></li>
<li><a class="reference internal" href="#filterestimator" id="id8">FilterEstimator</a></li>
</ul>
</li>
<li><a class="reference internal" href="#spatial-filters" id="id9">Spatial filters</a><ul>
<li><a class="reference internal" href="#common-spatial-pattern" id="id10">Common Spatial Pattern</a></li>
<li><a class="reference internal" href="#source-power-comodulation-spoc" id="id11">Source Power Comodulation (SPoC)</a></li>
<li><a class="reference internal" href="#xdawn" id="id12">xDAWN</a></li>
<li><a class="reference internal" href="#effect-matched-spatial-filtering" id="id13">Effect-matched spatial filtering</a></li>
<li><a class="reference internal" href="#patterns-vs-filters" id="id14">Patterns vs. filters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sensor-space-decoding" id="id15">Sensor-space decoding</a><ul>
<li><a class="reference internal" href="#decoding-over-time" id="id16">Decoding over time</a></li>
<li><a class="reference internal" href="#temporal-generalization" id="id17">Temporal Generalization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#source-space-decoding" id="id18">Source-space decoding</a></li>
<li><a class="reference internal" href="#references" id="id19">References</a></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="decoding-in-mne">
<span id="decoding"></span><h1><a class="toc-backref" href="#id3">Decoding in MNE</a><a class="headerlink" href="#decoding-in-mne" title="Permalink to this headline">¶</a></h1>
<p>For maximal compatibility with the Scikit-learn package, we follow the same API. Each estimator implements a <code class="docutils literal"><span class="pre">fit</span></code>, a <code class="docutils literal"><span class="pre">transform</span></code> and a <code class="docutils literal"><span class="pre">fit_transform</span></code> method. In some cases, they also implement an <code class="docutils literal"><span class="pre">inverse_transform</span></code> method. For more details, visit the Scikit-learn page.</p>
<p>For ease of comprehension, we will denote instantiations of the class using the same name as the class but in small caps instead of camel cases.</p>
<div class="section" id="basic-estimators">
<h2><a class="toc-backref" href="#id4">Basic Estimators</a><a class="headerlink" href="#basic-estimators" title="Permalink to this headline">¶</a></h2>
<div class="section" id="scaler">
<h3><a class="toc-backref" href="#id5">Scaler</a><a class="headerlink" href="#scaler" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference internal" href="../generated/mne.decoding.Scaler.html#mne.decoding.Scaler" title="mne.decoding.Scaler"><code class="xref py py-class docutils literal"><span class="pre">mne.decoding.Scaler</span></code></a> will standardize the data based on channel scales. In the simplest modes <code class="docutils literal"><span class="pre">scalings=None</span></code> or <code class="docutils literal"><span class="pre">scalings=dict(...)</span></code>, each data channel type (e.g., mag, grad, eeg) is treated separately and scaled by a constant. This is the approach used by e.g., <a class="reference internal" href="../generated/mne.compute_covariance.html#mne.compute_covariance" title="mne.compute_covariance"><code class="xref py py-func docutils literal"><span class="pre">mne.compute_covariance()</span></code></a> to standardize channel scales.</p>
<p>If <code class="docutils literal"><span class="pre">scalings='mean'</span></code> or <code class="docutils literal"><span class="pre">scalings='median'</span></code>, each channel is scaled using empirical measures. Each channel is scaled independently by the mean and standand deviation, or median and interquartile range, respectively, across all epochs and time points during <a class="reference internal" href="../generated/mne.decoding.Scaler.html#mne.decoding.Scaler.fit" title="mne.decoding.Scaler.fit"><code class="xref py py-class docutils literal"><span class="pre">mne.decoding.Scaler.fit</span></code></a> (during training). The <a class="reference internal" href="../generated/mne.decoding.Scaler.html#mne.decoding.Scaler.transform" title="mne.decoding.Scaler.transform"><code class="xref py py-meth docutils literal"><span class="pre">mne.decoding.Scaler.transform()</span></code></a> method is called to transform data (training or test set) by scaling all time points and epochs on a channel-by-channel basis. To perform both the <code class="docutils literal"><span class="pre">fit</span></code> and <code class="docutils literal"><span class="pre">transform</span></code> operations in a single call, the <a class="reference internal" href="../generated/mne.decoding.Scaler.html#mne.decoding.Scaler.fit_transform" title="mne.decoding.Scaler.fit_transform"><code class="xref py py-meth docutils literal"><span class="pre">mne.decoding.Scaler.fit_transform()</span></code></a> method may be used. To invert the transform, <a class="reference internal" href="../generated/mne.decoding.Scaler.html#mne.decoding.Scaler.inverse_transform" title="mne.decoding.Scaler.inverse_transform"><code class="xref py py-meth docutils literal"><span class="pre">mne.decoding.Scaler.inverse_transform()</span></code></a> can be used. For <code class="docutils literal"><span class="pre">scalings='median'</span></code>, <a class="reference external" href="http://scikit-learn.org/stable/">scikit-learn</a> version 0.17+ is required.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This is different from directly applying <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="(in scikit-learn v0.19.1)"><code class="xref py py-class docutils literal"><span class="pre">sklearn.preprocessing.StandardScaler</span></code></a> or <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler" title="(in scikit-learn v0.19.1)"><code class="xref py py-class docutils literal"><span class="pre">sklearn.preprocessing.RobustScaler</span></code></a> offered by <a class="reference external" href="http://scikit-learn.org/stable/">scikit-learn</a>. The <code class="docutils literal"><span class="pre">StandardScaler</span></code> and <code class="docutils literal"><span class="pre">RobustScaler</span></code> scale each <em>classification feature</em>, e.g. each time point for each channel, with mean and standard deviation computed across epochs, whereas <code class="docutils literal"><span class="pre">Scaler</span></code> scales each <em>channel</em> using mean and standard deviation computed across all of its time points and epochs.</p>
</div>
</div>
<div class="section" id="vectorizer">
<h3><a class="toc-backref" href="#id6">Vectorizer</a><a class="headerlink" href="#vectorizer" title="Permalink to this headline">¶</a></h3>
<p>Scikit-learn API provides functionality to chain transformers and estimators by using <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v0.19.1)"><code class="xref py py-class docutils literal"><span class="pre">sklearn.pipeline.Pipeline</span></code></a>. We can construct decoding pipelines and perform cross-validation and grid-search. However scikit-learn transformers and estimators generally expect 2D data (n_samples * n_features), whereas MNE transformers typically output data with a higher dimensionality (e.g. n_samples * n_channels * n_frequencies * n_times). A Vectorizer therefore needs to be applied between the MNE and the scikit-learn steps: e.g: make_pipeline(Xdawn(), Vectorizer(), LogisticRegression())</p>
</div>
<div class="section" id="psdestimator">
<h3><a class="toc-backref" href="#id7">PSDEstimator</a><a class="headerlink" href="#psdestimator" title="Permalink to this headline">¶</a></h3>
<p>This estimator computes the power spectral density (PSD) using the multitaper method. It takes a 3D array as input, it into 2D and computes the PSD.</p>
</div>
<div class="section" id="filterestimator">
<h3><a class="toc-backref" href="#id8">FilterEstimator</a><a class="headerlink" href="#filterestimator" title="Permalink to this headline">¶</a></h3>
<p>This estimator filters the 3D epochs data.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This is meant for use in conjunction with <code class="docutils literal"><span class="pre">RtEpochs</span></code>. It is not recommended in a normal processing pipeline as it may result in edge artifacts.</p>
</div>
</div>
</div>
<div class="section" id="spatial-filters">
<h2><a class="toc-backref" href="#id9">Spatial filters</a><a class="headerlink" href="#spatial-filters" title="Permalink to this headline">¶</a></h2>
<p>Just like temporal filters, spatial filters provide weights to modify the data along the sensor dimension. They are popular in the BCI community because of their simplicity and ability to distinguish spatially-separated neural activity.</p>
<div class="section" id="common-spatial-pattern">
<h3><a class="toc-backref" href="#id10">Common Spatial Pattern</a><a class="headerlink" href="#common-spatial-pattern" title="Permalink to this headline">¶</a></h3>
<p>This is a technique to analyze multichannel data based on recordings from two classes. Let <span class="math">\(X \in R^{C\times T}\)</span> be a segment of data with <span class="math">\(C\)</span> channels and <span class="math">\(T\)</span> time points. The data at a single time point is denoted by <span class="math">\(x(t)\)</span> such that <span class="math">\(X=[x(t), x(t+1), ..., x(t+T-1)]\)</span>. Common Spatial Pattern (CSP) finds a decomposition that projects the signal in the original sensor space to CSP space using the following transformation:</p>
<div class="math" id="equation-csp">
<span class="eqno">(1)<a class="headerlink" href="#equation-csp" title="Permalink to this equation">¶</a></span>\[x_{CSP}(t) = W^{T}x(t)\]</div>
<p>where each column of <span class="math">\(W \in R^{C\times C}\)</span> is a spatial filter and each row of <span class="math">\(x_{CSP}\)</span> is a CSP component. The matrix <span class="math">\(W\)</span> is also called the de-mixing matrix in other contexts. Let <span class="math">\(\Sigma^{+} \in R^{C\times C}\)</span> and <span class="math">\(\Sigma^{-} \in R^{C\times C}\)</span> be the estimates of the covariance matrices of the two conditions.
CSP analysis is given by the simultaneous diagonalization of the two covariance matrices</p>
<div class="math" id="equation-diagonalize_p">
<span class="eqno">(2)<a class="headerlink" href="#equation-diagonalize_p" title="Permalink to this equation">¶</a></span>\[W^{T}\Sigma^{+}W = \lambda^{+}\]</div>
<div class="math" id="equation-diagonalize_n">
<span class="eqno">(3)<a class="headerlink" href="#equation-diagonalize_n" title="Permalink to this equation">¶</a></span>\[W^{T}\Sigma^{-}W = \lambda^{-}\]</div>
<p>where <span class="math">\(\lambda^{C}\)</span> is a diagonal matrix whose entries are the eigenvalues of the following generalized eigenvalue problem</p>
<div class="math" id="equation-eigen_problem">
<span class="eqno">(4)<a class="headerlink" href="#equation-eigen_problem" title="Permalink to this equation">¶</a></span>\[\Sigma^{+}w = \lambda \Sigma^{-}w\]</div>
<p>Large entries in the diagonal matrix corresponds to a spatial filter which gives high variance in one class but low variance in the other. Thus, the filter facilitates discrimination between the two classes.</p>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_csp_eeg.html#sphx-glr-auto-examples-decoding-plot-decoding-csp-eeg-py"><span class="std std-ref">Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</span></a></li>
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_csp_space.html#sphx-glr-auto-examples-decoding-plot-decoding-csp-space-py"><span class="std std-ref">Decoding in sensor space data using the Common Spatial Pattern (CSP)</span></a></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">Spotlight:</p>
<p>The winning entry of the Grasp-and-lift EEG competition in Kaggle uses the CSP implementation in MNE. It was featured as a <a class="reference external" href="http://blog.kaggle.com/2015/08/12/july-2015-scripts-of-the-week/">script of the week</a>.</p>
</div>
</div>
<div class="section" id="source-power-comodulation-spoc">
<h3><a class="toc-backref" href="#id11">Source Power Comodulation (SPoC)</a><a class="headerlink" href="#source-power-comodulation-spoc" title="Permalink to this headline">¶</a></h3>
<p>Source Power Comodulation (SPoC) <a class="footnote-reference" href="#id2" id="id1">[1]</a> allows to identify the composition of orthogonal spatial filters that maximally correlate with a continuous target.</p>
<p>SPoC can be seen as an extension of the CSP where the target is driven by a continuous variable rather than a discrete variable. Typical applications include extraction of motor patterns using EMG power or audio patterns using sound envelope.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_spoc_CMC.html#sphx-glr-auto-examples-decoding-plot-decoding-spoc-cmc-py"><span class="std std-ref">Continuous Target Decoding with SPoC</span></a></li>
</ul>
</div>
</div>
<div class="section" id="xdawn">
<h3><a class="toc-backref" href="#id12">xDAWN</a><a class="headerlink" href="#xdawn" title="Permalink to this headline">¶</a></h3>
<p>Xdawn is a spatial filtering method designed to improve the signal to signal + noise ratio (SSNR) of the ERP responses. Xdawn was originally  designed for P300 evoked potential by enhancing the target response with respect to the non-target response. The implementation in MNE-Python is a generalization to any type of ERP.</p>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/preprocessing/plot_xdawn_denoising.html#sphx-glr-auto-examples-preprocessing-plot-xdawn-denoising-py"><span class="std std-ref">XDAWN Denoising</span></a></li>
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_xdawn_eeg.html#sphx-glr-auto-examples-decoding-plot-decoding-xdawn-eeg-py"><span class="std std-ref">XDAWN Decoding From EEG data</span></a></li>
</ul>
</div>
</div>
<div class="section" id="effect-matched-spatial-filtering">
<h3><a class="toc-backref" href="#id13">Effect-matched spatial filtering</a><a class="headerlink" href="#effect-matched-spatial-filtering" title="Permalink to this headline">¶</a></h3>
<p>The result is a spatial filter at each time point and a corresponding time course. Intuitively, the result gives the similarity between the filter at each time point and the data vector (sensors) at that time point.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_ems_filtering.html#sphx-glr-auto-examples-decoding-plot-ems-filtering-py"><span class="std std-ref">Compute effect-matched-spatial filtering (EMS)</span></a></li>
</ul>
</div>
</div>
<div class="section" id="patterns-vs-filters">
<h3><a class="toc-backref" href="#id14">Patterns vs. filters</a><a class="headerlink" href="#patterns-vs-filters" title="Permalink to this headline">¶</a></h3>
<p>When interpreting the components of the CSP, it is often more intuitive to think about how <span class="math">\(x(t)\)</span> is composed of the different CSP components <span class="math">\(x_{CSP}(t)\)</span>. In other words, we can rewrite Equation <a class="reference internal" href="#equation-csp">(1)</a> as follows:</p>
<div class="math" id="equation-patterns">
<span class="eqno">(5)<a class="headerlink" href="#equation-patterns" title="Permalink to this equation">¶</a></span>\[x(t) = (W^{-1})^{T}x_{CSP}(t)\]</div>
<p>The columns of the matrix <span class="math">\((W^{-1})^T\)</span> are called spatial patterns. This is also called the mixing matrix. The example <a class="reference internal" href="../auto_examples/decoding/plot_linear_model_patterns.html#sphx-glr-auto-examples-decoding-plot-linear-model-patterns-py"><span class="std std-ref">Linear classifier on sensor data with plot patterns and filters</span></a> demonstrates the difference between patterns and filters.</p>
<p>Plotting a pattern is as simple as doing:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">info</span> <span class="o">=</span> <span class="n">epochs</span><span class="o">.</span><span class="n">info</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">plot_patterns</span><span class="p">(</span><span class="n">info</span><span class="p">)</span>  <span class="c1"># model is an instantiation of an estimator described in this section  </span>
</pre></div>
</div>
<a class="reference internal image-reference" href="manual/../../_images/sphx_glr_plot_linear_model_patterns_001.png"><img alt="manual/../../_images/sphx_glr_plot_linear_model_patterns_001.png" class="align-center" src="manual/../../_images/sphx_glr_plot_linear_model_patterns_001.png" style="height: 100px;" /></a>
<p>To plot the corresponding filter, you can do:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">plot_filters</span><span class="p">(</span><span class="n">info</span><span class="p">)</span>  
</pre></div>
</div>
<a class="reference internal image-reference" href="manual/../../_images/sphx_glr_plot_linear_model_patterns_002.png"><img alt="manual/../../_images/sphx_glr_plot_linear_model_patterns_002.png" class="align-center" src="manual/../../_images/sphx_glr_plot_linear_model_patterns_002.png" style="height: 100px;" /></a>
</div>
</div>
<div class="section" id="sensor-space-decoding">
<h2><a class="toc-backref" href="#id15">Sensor-space decoding</a><a class="headerlink" href="#sensor-space-decoding" title="Permalink to this headline">¶</a></h2>
<div class="section" id="decoding-over-time">
<h3><a class="toc-backref" href="#id16">Decoding over time</a><a class="headerlink" href="#decoding-over-time" title="Permalink to this headline">¶</a></h3>
<p>This strategy consists in fitting a multivariate predictive model on each
time instant and evaluating its performance at the same instant on new
epochs. The <a class="reference internal" href="../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="mne.decoding.SlidingEstimator"><code class="xref py py-class docutils literal"><span class="pre">mne.decoding.SlidingEstimator</span></code></a> will take as input a
pair of features <span class="math">\(X\)</span> and targets <span class="math">\(y\)</span>, where <span class="math">\(X\)</span> has
more than 2 dimensions. For decoding over time the data <span class="math">\(X\)</span>
is the epochs data of shape n_epochs x n_channels x n_times. As the
last dimension of <span class="math">\(X\)</span> is the time an estimator will be fit
on every time instant.</p>
<p>This approach is analogous to SlidingEstimator-based approaches in fMRI,
where here we are interested in when one can discriminate experimental
conditions and therefore figure out when the effect of interest happens.</p>
<p>When working with linear models as estimators, this approach boils
down to estimating a discriminative spatial filter for each time instant.</p>
<a class="reference internal image-reference" href="manual/../../_images/sphx_glr_plot_decoding_sensors_001.png"><img alt="manual/../../_images/sphx_glr_plot_decoding_sensors_001.png" class="align-center" src="manual/../../_images/sphx_glr_plot_decoding_sensors_001.png" style="width: 400px;" /></a>
<p>To generate this plot see our tutorial <a class="reference internal" href="../auto_tutorials/plot_sensors_decoding.html#sphx-glr-auto-tutorials-plot-sensors-decoding-py"><span class="std std-ref">Decoding sensor space data (MVPA)</span></a>.</p>
</div>
<div class="section" id="temporal-generalization">
<h3><a class="toc-backref" href="#id17">Temporal Generalization</a><a class="headerlink" href="#temporal-generalization" title="Permalink to this headline">¶</a></h3>
<p>Temporal Generalization is an extension of the decoding over time approach.
It consists in evaluating whether the model estimated at a particular
time instant accurately predicts any other time instant. It is analogous to
transferring a trained model to a distinct learning problem, where the problems
correspond to decoding the patterns of brain activity recorded at distinct time
instants.</p>
<p>The object to for Temporal Generalization is
<a class="reference internal" href="../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator"><code class="xref py py-class docutils literal"><span class="pre">mne.decoding.GeneralizingEstimator</span></code></a>. It expects as input <span class="math">\(X\)</span> and
<span class="math">\(y\)</span> (similarly to <a class="reference internal" href="../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="mne.decoding.SlidingEstimator"><code class="xref py py-class docutils literal"><span class="pre">mne.decoding.SlidingEstimator</span></code></a>) but, when generate
predictions from each model for all time instants. The class
<a class="reference internal" href="../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator"><code class="xref py py-class docutils literal"><span class="pre">mne.decoding.GeneralizingEstimator</span></code></a> is generic and will treat the last
dimension as the one to be used for generalization testing. For convenience,
here, we refer to it different tasks. If <span class="math">\(X\)</span> corresponds to epochs data
then the last dimension is time.</p>
<a class="reference internal image-reference" href="manual/../../_images/sphx_glr_plot_decoding_time_generalization_001.png"><img alt="manual/../../_images/sphx_glr_plot_decoding_time_generalization_001.png" class="align-center" src="manual/../../_images/sphx_glr_plot_decoding_time_generalization_001.png" style="width: 400px;" /></a>
<p>To generate this plot see our tutorial <a class="reference internal" href="../auto_tutorials/plot_sensors_decoding.html#sphx-glr-auto-tutorials-plot-sensors-decoding-py"><span class="std std-ref">Decoding sensor space data (MVPA)</span></a>.</p>
</div>
</div>
<div class="section" id="source-space-decoding">
<h2><a class="toc-backref" href="#id18">Source-space decoding</a><a class="headerlink" href="#source-space-decoding" title="Permalink to this headline">¶</a></h2>
<p>Source space decoding is also possible, but because the number of features can be much larger than in the sensor space, univariate feature selection using ANOVA f-test (or some other metric) can be done to reduce the feature dimension. Interpreting decoding results might be easier in source space as compared to sensor space.</p>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_spatio_temporal_source.html#sphx-glr-auto-examples-decoding-plot-decoding-spatio-temporal-source-py"><span class="std std-ref">Decoding source space data</span></a></li>
</ul>
</div>
</div>
<div class="section" id="references">
<h2><a class="toc-backref" href="#id19">References</a><a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>Dahne, S., Meinecke, F. C., Haufe, S., Hohne, J., Tangermann, M., Muller, K. R., &amp; Nikulin, V. V. (2014). SPoC: a novel framework for relating the amplitude of neuronal oscillations to behaviorally relevant parameters. NeuroImage, 86, 111-122.</td></tr>
</tbody>
</table>
</div>
</div>


    </div>
    
  </div>
</div>
<footer class="footer">
  <div class="container"><img src="../_static/institutions.png" alt="Institutions"></div>
  <div class="container">
    <ul class="list-inline">
      <li><a href="https://github.com/mne-tools/mne-python">GitHub</a></li>
      <li>·</li>
      <li><a href="https://mail.nmr.mgh.harvard.edu/mailman/listinfo/mne_analysis">Mailing list</a></li>
      <li>·</li>
      <li><a href="https://gitter.im/mne-tools/mne-python">Gitter</a></li>
      <li>·</li>
      <li><a href="whats_new.html">What's new</a></li>
      <li>·</li>
      <li><a href="faq.html#cite">Cite MNE</a></li>
      <li class="pull-right"><a href="#">Back to top</a></li>
    </ul>
    <p>&copy; Copyright 2012-2017, MNE Developers. Last updated on 2017-10-31.</p>
  </div>
</footer>
<script src="https://mne.tools/versionwarning.js"></script>
  </body>
</html>